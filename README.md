# Data Scientist

### Education
- B.S. Biological Sciences with Chemistry Minor | Wayne State University at Detroit, Michigan (Transfer Student) (_May 2023 - August 2024_)
- B.S. Biochemistry and Biomedical Sciences | University of Windsor at Windsor, Canada (_September 2021 - April 2023_)
- AAB Business Administration | RRC Polytech at Winnipeg, Canada (_August 2015 - July 2017_)

### Work Experience
**Data Scientist (Remote) @ Randeep Paper Board Mills- Chemical Division, India (_September 2021 - Present_)**
- Develop and maintain interactive dashboards in Salesforce and Power BI, providing real-time, cross-platform insights into key performance metrics.
- Build and customize standard reports in Salesforce, consolidating data from multiple sources to track KPIs.
- Create and maintain detailed documentation for both Salesforce and Power BI workflows.

**Student Research Assistant @ Wayne State University School of Medicine, Michigan (_June 2023 - May 2024_)**
- Utilized Cloud LMS and Biologics LMS for efficient data management and analysis of biological samples
- Collaborated with cross-functional teams to perform ad hoc analyses and deliver actionable insights on cell division mechanisms.
- Conducted and set up experiments to investigate mechanisms of cytokinesis in C. elegans, ensuring accurate data collection and analysis.

**Data Analyst – R&D Intern @ Maruti Suzuki India Ltd., India (_Jan 2021 - August 2021_)**
- Developed and maintained dashboards and reports to visualize key performance indicators and project metrics.
-  Collaborated with cross-functional teams to support research and development projects, enhancing datadriven decision-making processes.
- Worked closely with Data Scientists on multiple data analysis use cases, leveraging Git and Jira for version control and project management.

### Projects
### 1. End-to-End Customer Churn Data Prediction Model using AI/ML
**Project Overview**
- Customer churn refers to the phenomenon where customers stop using a company’s product or service. It is a critical metric for businesses, as high churn rates can significantly impact revenue and profitability. By predicting which customers are likely to churn, businesses can develop targeted strategies to retain them, thereby reducing the churn rate and increasing customer lifetime value.
- The project successfully demonstrated the capability to automate a machine learning pipeline and deploy it in an interactive web application. The ability to manage complex tools like Apache Airflow and Streamlit, coupled with overcoming technical hurdles on a Windows-based development environment, highlights a strong foundation in both software development and machine learning operations (MLOps).

**Project Description**
- This project involved the development and deployment of a machine learning model for predicting customer churn. The pipeline was built using a range of tools including Apache Airflow for automation, Airbyte for data ingestion, Snowflake for data warehousing, Tableau for exploratory data analysis (EDA), and Streamlit for creating an interactive web application. The project demonstrates both technical expertise and a deep understanding of how data-driven solutions can be leveraged to drive business value.
- The primary objective was to create an automated, scalable pipeline that could continuously process data, train a model, and provide real-time predictions of customer churn. The project showcases how advanced machine learning techniques can be integrated into business processes to identify potential customer churn early, allowing companies to take proactive measures to retain customers.

**Skills Utilized**
- Programming Languages: Python
- Data Ingestion and ELT: Airbyte
- Data Warehousing: Snowflake
- Data Visualization: Tableau
- Machine Learning: Scikit-learn (Random Forest Classifier)
- Data Preprocessing: Label Encoding, One-Hot Encoding, StandardScaler
- Exploratory Data Analysis (EDA): Data Visualization, Feature Engineering
- Automation and Orchestration: Apache Airflow (DAG creation, task automation)
- Web Application Development: Streamlit
- Cloud Services: AWS S3 (model storage and retrieval)
- Data Source: Kaggle
- Version Control: Git (for managing code and collaboration)
- Problem Solving: Overcoming WSL setup challenges, configuring a Unix-like environment on Windows, and ensuring cross-platform compatibility.

### 2. Website: Locomotion
**Project Overview**
- As a biological sciences major, I wanted to present my final project in an engaging and accessible way through a web application.
- The objective was to demonstrate not only my knowledge of biological locomotion but also my technical skills in web development. By creating this project, I was able to showcase my proficiency in building dynamic, responsive websites that effectively communicate scientific content to a broad audience.

**Project Description**
- This project involved the development of a web-based platform focused on the exploration of locomotion mechanisms across various species.
- The goal was to create an educational and informative resource that highlights the diverse adaptations of animals for movement.
- Although the topic is grounded in biological science, the focus of this project was on utilizing web development skills, specifically HTML, CSS, and JavaScript, to create an interactive and visually appealing interface. The website serves as a demonstration of coding knowledge and the ability to effectively communicate complex information through a web application.

**Skills Utilized**
- Web Development: HTML, CSS, JavaScript
