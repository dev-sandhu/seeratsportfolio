# Data Scientist

### Education
- B.S. Biological Sciences with Chemistry Minor | Wayne State University at Detroit, Michigan (Transfer Student) (_May 2023 - August 2024_)
- B.S. Biochemistry and Biomedical Sciences | University of Windsor at Windsor, Canada (_September 2021 - April 2023_)
- AAB Business Administration | RRC Polytech at Winnipeg, Canada (_August 2015 - July 2017_)

### Work Experience
**Data Scientist (Remote) @ Randeep Paper Board Mills- Chemical Division, India (_September 2021 - Present_)**
- Develop and maintain interactive dashboards in Salesforce and Power BI, providing real-time, cross-platform insights into key performance metrics.
- Build and customize standard reports in Salesforce, consolidating data from multiple sources to track KPIs.
- Create and maintain detailed documentation for both Salesforce and Power BI workflows.

**Student Research Assistant @ Wayne State University School of Medicine, Michigan (_June 2023 - May 2024_)**
- Utilized Cloud LMS and Biologics LMS for efficient data management and analysis of biological samples
- Collaborated with cross-functional teams to perform ad hoc analyses and deliver actionable insights on cell division mechanisms.
- Conducted and set up experiments to investigate mechanisms of cytokinesis in C. elegans, ensuring accurate data collection and analysis.

**Data Analyst – R&D Intern @ Maruti Suzuki India Ltd., India (_Jan 2021 - August 2021_)**
- Developed and maintained dashboards and reports to visualize key performance indicators and project metrics.
-  Collaborated with cross-functional teams to support research and development projects, enhancing datadriven decision-making processes.
- Worked closely with Data Scientists on multiple data analysis use cases, leveraging Git and Jira for version control and project management.

### Projects
### 1. End-to-End Customer Churn Data Prediction Model using AI/ML
**Project Overview**
- Customer churn refers to the phenomenon where customers stop using a company’s product or service. It is a critical metric for businesses, as high churn rates can significantly impact revenue and profitability. By predicting which customers are likely to churn, businesses can develop targeted strategies to retain them, thereby reducing the churn rate and increasing customer lifetime value.
- The project successfully demonstrated the capability to automate a machine learning pipeline and deploy it in an interactive web application. The ability to manage complex tools like Apache Airflow and Streamlit, coupled with overcoming technical hurdles on a Windows-based development environment, highlights a strong foundation in both software development and machine learning operations (MLOps).

**Project Description**
- This project involved the development and deployment of a machine learning model for predicting customer churn. The pipeline was built using a range of tools including Apache Airflow for automation, Airbyte for data ingestion, Snowflake for data warehousing, Tableau for exploratory data analysis (EDA), and Streamlit for creating an interactive web application. The project demonstrates both technical expertise and a deep understanding of how data-driven solutions can be leveraged to drive business value.
- The primary objective was to create an automated, scalable pipeline that could continuously process data, train a model, and provide real-time predictions of customer churn. The project showcases how advanced machine learning techniques can be integrated into business processes to identify potential customer churn early, allowing companies to take proactive measures to retain customers.

**Skills Utilized**
- Programming Languages: Python
- Data Ingestion and ELT: Airbyte
- Data Warehousing: Snowflake
- Data Visualization: Salesforce Analytics Studio, PowerBI, Tableau
- Machine Learning: Scikit-learn (Random Forest Classifier)
- Data Preprocessing: Label Encoding, One-Hot Encoding, StandardScaler
- Exploratory Data Analysis (EDA): Data Visualization, Feature Engineering
- Automation and Orchestration: Apache Airflow (DAG creation, task automation)
- Web Application Development: Streamlit
- Cloud Services: AWS S3 (model storage and retrieval)
- Data Source: Kaggle
- Version Control: Git (for managing code and collaboration)
- Problem Solving: Overcoming WSL setup challenges, configuring a Unix-like environment on Windows, and ensuring cross-platform compatibility.

### 2. Sign Language Interpreter Model Using Deep Learning and Machine Learning
**Project Overview**
- This project focuses on bridging the communication gap for the deaf and hard-of-hearing communities by building a model that interprets American Sign Language (ASL) gestures into readable text. Utilizing deep learning techniques, the model identifies and translates hand gestures, making it an essential tool for enhancing accessibility and inclusivity.
- The project demonstrates expertise in computer vision, deep learning, and model deployment, culminating in a real-time, interactive sign language interpreter. The solution leverages advanced neural networks to ensure accurate gesture recognition, showcasing a strong foundation in machine learning for social impact.

**Project Description**
- The sign language interpreter project involves developing a deep learning model that uses computer vision to recognize hand gestures and translate them into readable text. The model pipeline includes data preprocessing, model training, and real-time gesture recognition. Tools such as OpenCV for image processing, TensorFlow/Keras for deep learning model development, and a custom script for webcam integration make up the project's technical framework.
- The primary objective was to create an accessible, interactive model that can recognize ASL gestures in real time, providing users with instant text-based feedback. The project demonstrates how AI can be applied to address communication barriers, with potential applications in educational and assistive technologies.

**Skills Utilized**
- Programming Languages: Python
- Computer Vision: OpenCV (for image capture and processing)
- Machine Learning and Deep Learning: TensorFlow, Keras (Convolutional Neural Networks for gesture recognition)
- Data Preprocessing: Image Augmentation, Resizing, Grayscale Conversion
- Data Visualization: PowerBI, Matplotlib (for analyzing model performance and training insights)
- Model Training and Tuning: CNN architecture design, Hyperparameter tuning, Data augmentation
- Automation and Pipeline Development: Python scripting to automate data preprocessing, model training, and real-time gesture recognition
- Deployment: Integration with webcam for live gesture input and real-time feedback loop
- Cloud Services: AWS S3 (for model and data storage)
- Version Control: Git (for tracking project progress and collaboration)
- Problem Solving: Overcoming challenges in real-time video processing, ensuring robust and accurate gesture recognition across varying lighting conditions, and fine-tuning the model for high accuracy
tibility.
